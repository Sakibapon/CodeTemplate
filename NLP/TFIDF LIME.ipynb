{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n#for text pre-processing\nimport re, string\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n#for model-building\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix,roc_curve,auc, accuracy_score\n# bag of words\nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n\n# for LIME import necessary packages\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\nfrom sklearn.pipeline import make_pipeline\nfrom lime.lime_text import IndexedString,IndexedCharacters\nfrom lime.lime_base import LimeBase\nfrom sklearn.linear_model import Ridge, lars_path\nfrom lime.lime_text import explanation\nfrom functools import partial\nimport scipy as sp\nfrom sklearn.utils import check_random_state","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-21T21:12:27.973733Z","iopub.execute_input":"2022-06-21T21:12:27.974150Z","iopub.status.idle":"2022-06-21T21:12:27.984567Z","shell.execute_reply.started":"2022-06-21T21:12:27.974113Z","shell.execute_reply":"2022-06-21T21:12:27.983508Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Read the data\ndf_train=pd.read_csv(\"../input/sarcasmcleandata/SarcasmCleanData.csv\")\n\n#convert to lowercase, strip and remove punctuations\ndef preprocess(text):\n    text = text.lower() \n    text=text.strip()  \n    text=re.compile('<.*?>').sub('', text) \n    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n    text = re.sub('\\s+', ' ', text)  \n    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n    text = re.sub(r'\\d',' ',text) \n    text = re.sub(r'\\s+',' ',text)\n    text=' '.join([i for i in text.split() if i not in stopwords.words('english')])\n    return text\n\n#LEMMATIZATION\n# Initialize the lemmatizer\nwl = WordNetLemmatizer()\n# function to map NTLK position tags\n\ndef get_wordnet_pos(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n# Tokenize the sentence\ndef lemmatizer(string):\n    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n    return \" \".join(a)\ndef finalpreprocess(text):\n    return lemmatizer(preprocess(text))\ndf_train['cleaned_Comments'] = df_train['Comments'].apply(lambda x: finalpreprocess(x))\n\n#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\nX_train, X_val, y_train, y_val = train_test_split(df_train[\"Comments\"],df_train[\"Label\"],test_size=0.2, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TF-IDF ","metadata":{}},{"cell_type":"code","source":"# Convert x_train to vector\ntfidf_vectorizer = TfidfVectorizer(use_idf=True)\nX_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \nX_val_vectors_tfidf = tfidf_vectorizer.transform(X_val)\n#model\nmodel=RandomForestClassifier(n_estimators = 100, random_state = 10)\nmodel.fit(X_train_vectors_tfidf, y_train) \n\n#Predict y value for test dataset\ny_pred = model.predict(X_val_vectors_tfidf)\ny_prob = model.predict_proba(X_val_vectors_tfidf)[:,1]\n\nacc = sklearn.metrics.accuracy_score(y_val, y_pred)\nprint(\"Accuracy: {}\".format(acc))\n\nprint(classification_report(y_val,y_pred))\ncm = confusion_matrix(y_val, y_pred)\nprint('Confusion Matrix:',cm)\nf = sns.heatmap(cm, annot=True, fmt='d')\n\nfpr, tpr, thresholds = roc_curve(y_val, y_prob)\nroc_auc = auc(fpr, tpr)\nprint('AUC:', roc_auc)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:13:36.747106Z","iopub.execute_input":"2022-06-21T21:13:36.748013Z","iopub.status.idle":"2022-06-21T21:13:38.573574Z","shell.execute_reply.started":"2022-06-21T21:13:36.747943Z","shell.execute_reply":"2022-06-21T21:13:38.572392Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### LIME","metadata":{}},{"cell_type":"code","source":"for i in range(1,20):\n    print(X_val.iloc[i])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:14:03.387463Z","iopub.execute_input":"2022-06-21T21:14:03.387898Z","iopub.status.idle":"2022-06-21T21:14:03.393482Z","shell.execute_reply.started":"2022-06-21T21:14:03.387862Z","shell.execute_reply":"2022-06-21T21:14:03.392279Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Explaining the predictions and important features for predicting the label 1\nc = make_pipeline(tfidf_vectorizer, model)\nexplainer = LimeTextExplainer(class_names=model.classes_)\n\n# classifier_fn is the probability function that takes a string and returns prediction probabilities.\n# num_features is the max. number of features we want in the explanation(default is 10).\n# labels=(1,) means we want the explanation for the label 1\nfor i in range(1,50):\n    exp = explainer.explain_instance(X_val.iloc[i], c.predict_proba, num_features=5,labels=(1,))\n    exp.show_in_notebook()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T21:18:23.733821Z","iopub.execute_input":"2022-06-21T21:18:23.734626Z","iopub.status.idle":"2022-06-21T21:19:09.632131Z","shell.execute_reply.started":"2022-06-21T21:18:23.734581Z","shell.execute_reply":"2022-06-21T21:19:09.630793Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}